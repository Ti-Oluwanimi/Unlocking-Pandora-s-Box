# Unlocking-Pandora's Box
Unlocking Pandora's Box: Unveiling the Elusive Realm of AI Text Detection

## Abstract
<div align="justify">
Large language models (LLMs) like GPT have raised concerns about their potential misuse for academic dishonesty and other negative purposes. This study examines the ability of AI text detectors to accurately identify different types of essays, including those generated by LLMs. Experiments show that current text detection systems have limitations, indicating the need for further research and development in this area. Various text detector tools are evaluated and their performance on GPT-generated essays is discussed. The results highlight the challenges in distinguishing between human-written and GPT-generated content reliably. The importance of improving the models and algorithms used by text detectors to make them more robust and adaptable is stressed. Collaboration between LLM companies and text detection organizations is encouraged to effectively address the risks associated with their tools. By advancing AI text detection, the integrity of educational systems can be safeguarded and the risks of misusing GPT-generated text can be reduced.
</div>

## Main Results
The table below summarizes the classification accuracies of different AI text detectors on the essay samples:

| Essay Type    | Results (%)  | Sapling | Crossplag | OpenAI | ZeroGPT | GPTZero | Con.Scale |
|---------------|--------------|---------|-----------|--------|---------|---------|-----------|
|               | Human (%)    | 50.0    | 100.0     | 100.0  | 83.3    | 83.3    | 100.0     |
| Argumentative | GPT (%)      | 71.4    | 57.1      | 42.9   | 85.7    | 85.7    | 57.1      |
|               | Accuracy (%) | 61.5    | 76.9      | 69.2   | 84.6    | 84.6    | 76.9      |
|               |              |         |           |        |         |         |           |
|               | Human (%)    | 100.0   | 100.0     | 100.0  | 100.0   | 100.0   | 100.0     |
| Descriptive   | GPT (%)      | 44.4    | 55.6      | 11.1   | 55.6    | 66.7    | 37.5      |
|               | Accuracy (%) | 70.6    | 76.5      | 52.9   | 76.5    | 82.4    | 64.7      |
|               |              |         |           |        |         |         |           |
|               | Human (%)    | 100.0   | 100.0     | 80.0   | 80.0    | 80.0    | 100.0     |
| Expository    | GPT (%)      | 50.0    | 50.0      | 33.3   | 66.7    | 50.0    | 33.3      |
|               | Accuracy (%) | 72.7    | 72.7      | 54.5   | 72.7    | 63.6    | 63.6      |
|               |              |         |           |        |         |         |           |
|               | Human (%)    | 80.0    | 100.0     | 100.0  | 100.0   | 80.0    | 100.0     |
| Narrative     | GPT (%)      | 33.3    | 33.3      | 33.3   | 83.3    | 83.3    | 33.3      |
|               | Accuracy (%) | 54.5    | 63.6      | 63.6   | 90.9    | 81.8    | 63.6      |

## Foolproofing the text detectors
<div align="justify">
1. This table demonstrates the robustness of different AI Text Detector tools on GPT-Improved human-written essays. The values represent the detection scores achieved by each tool for different essay types.
</div>

| Essay Type    | Sapling | Crossplag | OpenAI | ZeroGPT | GPTZero | Con.Scale |
|---------------|---------|-----------|--------|---------|---------|-----------|
| Argumentative | 0.33    | 0.5       | 0.33   | 0.69    | 0.69    | 0.5       |
| Descriptive   | 0.38    | 0.5       | 0.0    | 0.5     | 0.63    | 0.25      |
| Expository    | 0.4     | 0.4       | 0.16   | 0.48    | 0.32    | 0.2       |
| Narrative     | 0.32    | 0.2       | 0.2    | 0.8     | 0.64    | 0.2       |

<div align="justify">
2. This table showcases the robustness of different AI Text Detector tools on GPT-generated human-like essays. The values indicate the detection scores achieved by each tool for different essay types.
</div>

| Essay Type    | Sapling | Crossplag | OpenAI | ZeroGPT | GPTZero | Con.Scale |
|---------------|---------|-----------|--------|---------|---------|-----------|
| Argumentative | 0       | 0         | 0      | 1       | 1       | 0         |
| Descriptive   | 0       | 0         | 0      | 1       | 1       | 0         |
| Expository    | 0       | 0         | 1      | 1       | 1       | 0         |
| Narrative     | 0       | 0         | 0      | 1       | 1       | 1         |

<div align="justify">
3. This table showcases the robustness of different AI Text Detector tools on GPT-generated blunder-filled essays. The values indicate the detection scores achieved by each tool for different essay types, with the sample size (n) mentioned for each category.
</div>

| Essay Type          | Sapling | Crossplag | OpenAI | ZeroGPT | GPTZero | Con.Scale |
|---------------------|---------|-----------|--------|---------|---------|-----------|
| Argumentative (n=5) | 0       | 0         | 0      | 3       | 4       | 0         |
| Descriptive (n=3)   | 0       | 0         | 0      | 0       | 0       | 0         |
| Expository (n=3)    | 0       | 0         | 0      | 0       | 0       | 0         |
| Narrative (n=2)     | 1       | 1         | 1      | 1       | 1       | 1         |

## Dataset Used
In this section, we describe the process of collecting data for our study. We focused on four types of essays, as outlined in the Method section.

Note that:

1. For each essay type, we gathered a minimum of five human-written samples from the web, using the prompts listed in the table above. To ensure that the samples were truly human-written, we only included those that were written and uploaded prior to the ChatGPT era (pre-2022).

2. Next, we generated one novel essay of each type using ChatGPT. We used the following prompt format:

```
Compose a/an [essay type] within a word limit of 500 words, addressing the following [prompt].
```

3. Finally, we generated GPT-improved versions of the human-written samples using the following prompt format:

```
Enhance the [essay type] below by refining its content and structure in response to the [prompt].
```


### Essay Types and Samples

| Essay Type    | Prompt                           | Samples | Word Range   |
|---------------|---------------------------------|---------|--------------|
| Argumentative | Gun Control                      | 13      | 526 - 1173   |
| Descriptive   | A Day at the Beach               | 17      | 331 - 1481   |
| Expository    | The Benefits of Regular Exercise | 11      | 314 - 803    |
| Narrative     | A Journey Towards Self-Discovery | 11      | 421 - 1558   |

Table showing the prompts, word range, and distribution of samples across all essay types.

### Sample Breakdown

| Essay Type    | Human-written | GPT-improved | ChatGPT | Total |
|---------------|---------------|--------------|---------|-------|
| Argumentative | 6             | 6            | 1       | 13    |
| Descriptive   | 8             | 8            | 1       | 17    |
| Expository    | 5             | 5            | 1       | 11    |
| Narrative     | 5             | 5            | 1       | 11    |

Table showing the breakdown of human-written, GPT-improved, and ChatGPT-generated samples.
