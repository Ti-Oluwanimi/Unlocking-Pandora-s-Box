# Unlocking-Pandora's Box
Unlocking Pandora's Box: Unveiling the Elusive Realm of AI Text Detection

## Abstract
<div align="justify">
The proliferation of large language models, such as GPT, has raised concerns about the potential misuse of generated text for academic dishonesty and other negative purposes. In this study, we explore the robustness of AI text detectors in accurately classifying various types of essays, including those generated by GPT. Our experiments reveal the limitations of current text detection systems, highlighting the need for further research and development in this field. We present an evaluation of different text detector tools and discuss their performance on GPT-generated essays. The results underscore the challenges in reliably distinguishing between human-written and GPT-generated content. We also emphasize the importance of refining the models and algorithms employed by text detectors to enhance their robustness and adaptability. Additionally, we advocate for collaboration between large language model companies and text detection organizations to effectively address the multi-sided risks which comes as a result of deploying their tools. By advancing the field of AI text detection, we can ensure the integrity of educational systems and mitigate the risks associated with the misuse of GPT-generated text.
</div>

## Main Results
The table below summarizes the classification accuracies of different AI text detectors on the essay samples:

| Essay Type    | Results (%)  | Sapling | Crossplag | OpenAI | ZeroGPT | GPTZero | Con.Scale |
|---------------|--------------|---------|-----------|--------|---------|---------|-----------|
|               | Human (%)    | 50.0    | 100.0     | 100.0  | 83.3    | 83.3    | 100.0     |
| Argumentative | GPT (%)      | 71.4    | 57.1      | 42.9   | 85.7    | 85.7    | 57.1      |
|               | Accuracy (%) | 61.5    | 76.9      | 69.2   | 84.6    | 84.6    | 76.9      |
|               |              |         |           |        |         |         |           |
|               | Human (%)    | 100.0   | 100.0     | 100.0  | 100.0   | 100.0   | 100.0     |
| Descriptive   | GPT (%)      | 44.4    | 55.6      | 11.1   | 55.6    | 66.7    | 37.5      |
|               | Accuracy (%) | 70.6    | 76.5      | 52.9   | 76.5    | 82.4    | 64.7      |
|               |              |         |           |        |         |         |           |
|               | Human (%)    | 100.0   | 100.0     | 80.0   | 80.0    | 80.0    | 100.0     |
| Expository    | GPT (%)      | 50.0    | 50.0      | 33.3   | 66.7    | 50.0    | 33.3      |
|               | Accuracy (%) | 72.7    | 72.7      | 54.5   | 72.7    | 63.6    | 63.6      |
|               |              |         |           |        |         |         |           |
|               | Human (%)    | 80.0    | 100.0     | 100.0  | 100.0   | 80.0    | 100.0     |
| Narrative     | GPT (%)      | 33.3    | 33.3      | 33.3   | 83.3    | 83.3    | 33.3      |
|               | Accuracy (%) | 54.5    | 63.6      | 63.6   | 90.9    | 81.8    | 63.6      |

## Foolproofing the text detectors
<div align="justify">
1. This table demonstrates the robustness of different AI Text Detector tools on GPT-Improved human-written essays. The values represent the detection scores achieved by each tool for different essay types.
</div>

| Essay Type    | Sapling | Crossplag | OpenAI | ZeroGPT | GPTZero | Con.Scale |
|---------------|---------|-----------|--------|---------|---------|-----------|
| Argumentative | 0.33    | 0.5       | 0.33   | 0.69    | 0.69    | 0.5       |
| Descriptive   | 0.38    | 0.5       | 0.0    | 0.5     | 0.63    | 0.25      |
| Expository    | 0.4     | 0.4       | 0.16   | 0.48    | 0.32    | 0.2       |
| Narrative     | 0.32    | 0.2       | 0.2    | 0.8     | 0.64    | 0.2       |

<div align="justify">
2. This table showcases the robustness of different AI Text Detector tools on GPT-generated human-like essays. The values indicate the detection scores achieved by each tool for different essay types.
</div>

| Essay Type    | Sapling | Crossplag | OpenAI | ZeroGPT | GPTZero | Con.Scale |
|---------------|---------|-----------|--------|---------|---------|-----------|
| Argumentative | 0       | 0         | 0      | 1       | 1       | 0         |
| Descriptive   | 0       | 0         | 0      | 1       | 1       | 0         |
| Expository    | 0       | 0         | 1      | 1       | 1       | 0         |
| Narrative     | 0       | 0         | 0      | 1       | 1       | 1         |

<div align="justify">
3. This table showcases the robustness of different AI Text Detector tools on GPT-generated blunder-filled essays. The values indicate the detection scores achieved by each tool for different essay types, with the sample size (n) mentioned for each category.
</div>

| Essay Type          | Sapling | Crossplag | OpenAI | ZeroGPT | GPTZero | Con.Scale |
|---------------------|---------|-----------|--------|---------|---------|-----------|
| Argumentative (n=5) | 0       | 0         | 0      | 3       | 4       | 0         |
| Descriptive (n=3)   | 0       | 0         | 0      | 0       | 0       | 0         |
| Expository (n=3)    | 0       | 0         | 0      | 0       | 0       | 0         |
| Narrative (n=2)     | 1       | 1         | 1      | 1       | 1       | 1         |

## Dataset Used
In this section, we describe the process of collecting data for our study. We focused on four types of essays, as outlined in the Method section.

Note that:

1. For each essay type, we gathered a minimum of five human-written samples from the web, using the prompts listed in the table above. To ensure that the samples were truly human-written, we only included those that were written and uploaded prior to the ChatGPT era (pre-2022).

2. Next, we generated one novel essay of each type using ChatGPT. We used the following prompt format:

```
Generate a/an [essay type] not exceeding 500 words on [prompt].
```

3. Finally, we generated GPT-improved versions of the human-written samples using the following prompt format:

```
Improve the quality of this [essay type] on [prompt].
```


### Essay Types and Samples

| Essay Type    | Prompt                           | Samples | Word Range   |
|---------------|---------------------------------|---------|--------------|
| Argumentative | Gun Control                      | 13      | 526 - 1173   |
| Descriptive   | A Day at the Beach               | 17      | 331 - 1481   |
| Expository    | The Benefits of Regular Exercise | 11      | 314 - 803    |
| Narrative     | A Journey Towards Self-Discovery | 11      | 421 - 1558   |

Table showing the prompts, word range, and distribution of samples across all essay types.

### Sample Breakdown

| Essay Type    | Human-written | GPT-improved | ChatGPT | Total |
|---------------|---------------|--------------|---------|-------|
| Argumentative | 6             | 6            | 1       | 13    |
| Descriptive   | 8             | 8            | 1       | 17    |
| Expository    | 5             | 5            | 1       | 11    |
| Narrative     | 5             | 5            | 1       | 11    |

Table showing the breakdown of human-written, GPT-improved, and ChatGPT-generated samples.
